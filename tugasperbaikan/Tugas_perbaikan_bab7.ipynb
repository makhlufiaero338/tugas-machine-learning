{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaIz5quDphQP6Wvtr5gF4z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/makhlufiaero338/tugas-machine-learning/blob/main/tugasperbaikan/Tugas_perbaikan_bab7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cJwimlpFK4l0"
      },
      "outputs": [],
      "source": [
        "# Import library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset: Load movie reviews\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "categories = ['rec.sport.baseball', 'sci.med']  # Example categories\n",
        "data = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Display sample data\n",
        "print(\"Sample Text:\")\n",
        "print(data.data[0])\n",
        "print(\"\\nTarget Classes:\", data.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8-MHM55Nvnm",
        "outputId": "58be6ce1-9687-4441-9520-75b27bbc2596"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Text:\n",
            "My family doctor and the physiotherapist (PT) she sent me to agree that the\n",
            "pain in my left shoulder is bursitis. I have an appointment with an orthpod\n",
            "(I love that, it's short for 'orthopedic surgeon, apparently) but while I'm\n",
            "waiting the PT is treating me.\n",
            "\n",
            "She's using hot packs, ultrasound, and lasers, but there's no improvement\n",
            "yet. In fact, I almost suspect it's getting worse.\n",
            "\n",
            "My real question is about the laser treatment. I can't easily imagine what\n",
            "the physical effect that could have on a deep tissue problem. Can anyone\n",
            "shed some light (so to speak) on the matter?\n",
            "\n",
            "Target Classes: ['rec.sport.baseball', 'sci.med']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "LqxqS-FjNwxz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sub-bab 3: Representing Text Data as Bag-of-Words\n",
        "vectorizer_bow = CountVectorizer()\n",
        "X_train_bow = vectorizer_bow.fit_transform(X_train)\n",
        "X_test_bow = vectorizer_bow.transform(X_test)\n",
        "\n",
        "print(\"\\nBag-of-Words Representation (Shape):\", X_train_bow.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXKOioJ2N1-q",
        "outputId": "c5a449f2-67ff-4262-d455-aadc0117b216"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bag-of-Words Representation (Shape): (1388, 19243)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sub-bab 6: Stopwords\n",
        "vectorizer_bow_stopwords = CountVectorizer(stop_words='english')\n",
        "X_train_bow_stop = vectorizer_bow_stopwords.fit_transform(X_train)\n",
        "print(\"\\nBag-of-Words without Stopwords (Shape):\", X_train_bow_stop.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz2mDOTCN5us",
        "outputId": "5a237417-1737-4752-a3ad-abc1931ed4e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bag-of-Words without Stopwords (Shape): (1388, 18946)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sub-bab 7: Rescaling the Data with tf-idf\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(\"\\nTF-IDF Representation (Shape):\", X_train_tfidf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy4drIVIN-tL",
        "outputId": "92da0837-7278-4713-baf2-4455bd7f5f6f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF Representation (Shape): (1388, 19243)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sub-bab 8: Investigating Model Coefficients\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Display top features per class\n",
        "def display_top_features(vectorizer, model, class_labels, n=10):\n",
        "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
        "    for i, class_label in enumerate(class_labels):\n",
        "        top_features = np.argsort(model.feature_log_prob_[i])[-n:]\n",
        "        print(f\"\\nTop features for class '{class_label}':\")\n",
        "        print(feature_names[top_features])\n",
        "\n",
        "display_top_features(tfidf_vectorizer, model, data.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuibcHZ8OCSJ",
        "outputId": "19a835ee-000a-41bc-d354-7298324b7479"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top features for class 'rec.sport.baseball':\n",
            "['it' 'you' 'is' 'that' 'and' 'of' 'in' 'he' 'to' 'the']\n",
            "\n",
            "Top features for class 'sci.med':\n",
            "['for' 'you' 'that' 'in' 'it' 'and' 'is' 'of' 'to' 'the']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sub-bab 9: Bag-of-Words with More Than One Word (n-Grams)\n",
        "ngram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
        "X_train_ngram = ngram_vectorizer.fit_transform(X_train)\n",
        "print(\"\\nBag-of-Words with n-Grams (Shape):\", X_train_ngram.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1Tm2pRUOT5L",
        "outputId": "e1127be9-eca4-481a-89a8-ebd9b87b016e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bag-of-Words with n-Grams (Shape): (1388, 140994)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sub-bab 11: Topic Modeling and Document Clustering (LDA)\n",
        "lda = LatentDirichletAllocation(n_components=2, random_state=42)\n",
        "lda.fit(X_train_bow)\n",
        "\n",
        "print(\"\\nTop words per topic:\")\n",
        "for idx, topic in enumerate(lda.components_):\n",
        "    top_words = [vectorizer_bow.get_feature_names_out()[i] for i in topic.argsort()[-10:]]\n",
        "    print(f\"Topic {idx}: {' '.join(top_words)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faN0KMIxOWPc",
        "outputId": "d96595de-6528-4244-9452-b27e054bf280"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top words per topic:\n",
            "Topic 0: you for it that is in and of to the\n",
            "Topic 1: cancer 92 10 edu to for in and the of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sub-bab 12: Evaluating the Model\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=data.target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-E7xJvYObD6",
        "outputId": "1636a9ea-6bae-4ce0-937e-dce42f689073"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "rec.sport.baseball       0.97      0.97      0.97       294\n",
            "           sci.med       0.97      0.97      0.97       302\n",
            "\n",
            "          accuracy                           0.97       596\n",
            "         macro avg       0.97      0.97      0.97       596\n",
            "      weighted avg       0.97      0.97      0.97       596\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sub-bab 13: Summary and Outlook\n",
        "print(\"\\nSummary:\")\n",
        "print(\"1. Bag-of-Words and TF-IDF are fundamental for text data representation.\")\n",
        "print(\"2. Stopwords and n-Grams enhance feature extraction.\")\n",
        "print(\"3. LDA helps in unsupervised topic discovery.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGDgnr7AOePT",
        "outputId": "29faba55-2745-4f8d-cbe0-8a52f99b421e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary:\n",
            "1. Bag-of-Words and TF-IDF are fundamental for text data representation.\n",
            "2. Stopwords and n-Grams enhance feature extraction.\n",
            "3. LDA helps in unsupervised topic discovery.\n"
          ]
        }
      ]
    }
  ]
}